{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "CkuKoMdNxJI1",
    "outputId": "2acb6aab-55d7-48e8-fcfd-696b78b1c13a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp\n",
       "0        1      1193       5  978300760\n",
       "1        1       661       3  978302109\n",
       "2        1       914       3  978301968"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id gender  age  occupation zip_code\n",
       "0        1      F    1          10    48067\n",
       "1        2      M   56          16    70072\n",
       "2        3      M   25          15    55117"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                    title                         genre\n",
       "0         1         Toy Story (1995)   Animation|Children's|Comedy\n",
       "1         2           Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2         3  Grumpier Old Men (1995)                Comedy|Romance"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000209, 4) (6040, 5) (3883, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display\n",
    "\n",
    "import torch\n",
    "\n",
    "# تحميل البيانات\n",
    "cols_dict = {\n",
    "    'ratings': ['user_id', 'movie_id', 'rating', 'timestamp'],\n",
    "    'users': ['user_id', 'gender', 'age', 'occupation', 'zip_code'],\n",
    "    'items': ['movie_id', 'title', 'genre']\n",
    "}\n",
    "dir = 'C:/Users/lenovo/Desktop/LinUCB-HybridRecommender/data/1m/'\n",
    "\n",
    "ratings_data = pd.read_csv(dir + 'ratings.dat', sep='::', names=cols_dict['ratings'], engine='python')\n",
    "users_data = pd.read_csv(dir + 'users.dat', sep='::', names=cols_dict['users'], engine='python')\n",
    "items_data = pd.read_csv(dir + 'movies.dat', sep='::', names=cols_dict['items'], encoding='latin-1', engine='python')\n",
    "\n",
    "display(ratings_data.head(3), users_data.head(3), items_data.head(3))\n",
    "print(ratings_data.shape, users_data.shape, items_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7LivXHwsx8Dp",
    "outputId": "b5f1ba25-4952-4084-86e8-0e892cda2158"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'gender', 'age', 'occupation', 'zip_code'], dtype='object')\n",
      "Index(['movie_id', 'title', 'genre'], dtype='object')\n",
      "Index(['user_id', 'movie_id', 'rating', 'timestamp'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# نسخة احتياطية\n",
    "users_data_og = users_data.copy(deep=True)\n",
    "items_data_og = items_data.copy(deep=True)\n",
    "ratings_data_og = ratings_data.copy(deep=True)\n",
    "print(users_data.columns)\n",
    "print(items_data.columns)\n",
    "print(ratings_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "10zoKlg6ygc2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Literal, Union\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import ndcg_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class Utils:\n",
    "    @staticmethod\n",
    "    def extract_year(items_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        '''\n",
    "        Extracts:\n",
    "            - Year from title\n",
    "\n",
    "        returns: Dataframes with extracted features\n",
    "        '''\n",
    "        # Extract year from title\n",
    "        items_df['year'] = items_df['title'].str.extract(r'\\((\\d{4})\\)').astype(int)\n",
    "\n",
    "        return items_df\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_category_avg_ratings(users_df: pd.DataFrame, items_df: pd.DataFrame, ratings_df: pd.DataFrame, k=0.6) -> pd.DataFrame:\n",
    "        '''\n",
    "        Extracts penalized average ratings for each category for each user using exponential decay penalty.\n",
    "\n",
    "        users_df: DataFrame containing user information.\n",
    "        items_df: DataFrame containing item information with categories as binary columns.\n",
    "        ratings_df: DataFrame containing user-item interactions and ratings.\n",
    "        k: Control factor for penalty steepness. Default is 0.6.\n",
    "\n",
    "        Returns a DataFrame with users and their penalized average ratings per category.\n",
    "        '''\n",
    "        # Create a copy of users_df to store features\n",
    "        features_df = users_df.copy()\n",
    "\n",
    "        # Define exponential penalty function\n",
    "        def exp_penalty(n, k=0.6):\n",
    "            return 1 / np.exp(k * n)\n",
    "\n",
    "        # Iterate over each category in the items_df (excluding non-categorical columns)\n",
    "        for category in items_df.columns[2:]:\n",
    "            # Get item IDs in the current category\n",
    "            category_items = items_df[items_df[category] == 1]['movie_id']\n",
    "\n",
    "            # Filter ratings_df to include only ratings for items in the current category\n",
    "            category_ratings = ratings_df[ratings_df['movie_id'].isin(category_items)]\n",
    "\n",
    "            # Group by user_id and calculate the average rating and count of ratings for the current category\n",
    "            user_stats = category_ratings.groupby('user_id')['rating'].agg(['mean', 'count']).reset_index()\n",
    "            user_stats.columns = ['user_id', f'user_avg_rating_{category}', f'count_rating_{category}']\n",
    "\n",
    "            # Merge the user stats into features_df\n",
    "            features_df = pd.merge(features_df, user_stats, on='user_id', how='left')\n",
    "\n",
    "            # Apply exponential penalty and calculate the penalized average rating for each user\n",
    "            features_df[f'user_avg_rating_{category}'] = (\n",
    "                (1 - exp_penalty(features_df[f'count_rating_{category}'], k)) * features_df[f'user_avg_rating_{category}']\n",
    "            )\n",
    "\n",
    "            # Fill missing values with 0\n",
    "            features_df[f'user_avg_rating_{category}'] = features_df[f'user_avg_rating_{category}'].fillna(0)\n",
    "\n",
    "        # Select only the relevant columns\n",
    "        cols = features_df.columns[:32].tolist() + [col for col in features_df.columns if col.startswith('user_avg_rating_')]\n",
    "        result_df = features_df[cols]\n",
    "\n",
    "        return result_df\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_category_freq(users_df: pd.DataFrame, items_df: pd.DataFrame, ratings_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        # Copy users_df to avoid modifying the original dataframe\n",
    "        freq_df = users_df.copy()\n",
    "\n",
    "        # Get total interactions for each user\n",
    "        total_interactions = ratings_df.groupby('user_id').size().reset_index(name='total_interactions')\n",
    "        freq_df = pd.merge(freq_df, total_interactions, on='user_id', how='left').fillna(0)\n",
    "\n",
    "        # Iterate over each category in the items_df (assuming categories are from the 3rd column onward)\n",
    "        for category in items_df.columns[2:]:\n",
    "            # Get movie_ids that belong to the current category\n",
    "            movie_ids_in_category = items_df[items_df[category] == 1]['movie_id']\n",
    "\n",
    "            # Count interactions in the current category for each user\n",
    "            category_interactions = ratings_df[ratings_df['movie_id'].isin(movie_ids_in_category)].groupby('user_id').size().reset_index(name=f'{category}_count')\n",
    "\n",
    "            # Merge category_interactions with freq_df\n",
    "            freq_df = pd.merge(freq_df, category_interactions, on='user_id', how='left').fillna(0)\n",
    "\n",
    "            # Calculate frequency of interactions for the current category\n",
    "            freq_df[f'freq_{category}'] = freq_df[f'{category}_count'] / freq_df['total_interactions']\n",
    "\n",
    "            # Drop the intermediate category count column\n",
    "            freq_df.drop(columns=[f'{category}_count'], inplace=True)\n",
    "\n",
    "        return freq_df.fillna(0).drop(columns=['total_interactions'])\n",
    "\n",
    "    @staticmethod\n",
    "    def extend_users_items(users_df: pd.DataFrame, items_df: pd.DataFrame, ratings_df: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        '''\n",
    "        Extends users and items dataframes to match the ratings dataframe\n",
    "        '''\n",
    "        # Extend users dataframe\n",
    "        users_df = pd.merge(users_df, ratings_df[['user_id']], on='user_id', how='right')\n",
    "\n",
    "        # Extend items dataframe\n",
    "        items_df = pd.merge(items_df, ratings_df[['movie_id']], on='movie_id', how='right')\n",
    "\n",
    "        return users_df, items_df\n",
    "\n",
    "    @staticmethod\n",
    "    def multi_hot_encode(df: pd.DataFrame, col: str, delimiter='|') -> pd.DataFrame:\n",
    "        '''\n",
    "        Multi hot encodes columns in a dataframe\n",
    "        '''\n",
    "        df_ = df.copy(deep=True)\n",
    "\n",
    "        # Change Children's to Children to match the other genres\n",
    "        df_[col] = df_[col].str.replace(\"Children's\", 'Children') if col == 'genre' else df_[col]\n",
    "\n",
    "        # split genres\n",
    "        df_[col] = df_[col].str.split(delimiter)\n",
    "\n",
    "        # Create a pivot table\n",
    "        pivot_df = df_.explode(col).pivot_table(index='movie_id', columns=col, aggfunc='size', fill_value=0).reset_index()\n",
    "\n",
    "        # Merge the pivot table with the original DataFrame on 'movie_id'\n",
    "        result = pd.merge(df, pivot_df, on='movie_id', how='left')\n",
    "\n",
    "        return result.drop(columns=[col])\n",
    "\n",
    "    @staticmethod\n",
    "    def one_hot_encode(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
    "        '''\n",
    "        One hot encodes columns in a dataframe\n",
    "        '''\n",
    "        return pd.get_dummies(df, columns=cols) * 1\n",
    "\n",
    "    @staticmethod\n",
    "    def move_column(df: pd.DataFrame, col: list[str], pos: int) -> pd.DataFrame:\n",
    "        '''\n",
    "        Moves a column to a specific position in a DataFrame\n",
    "        '''\n",
    "        cols = df.columns.tolist()\n",
    "        for i in reversed(col):\n",
    "            cols.insert(pos, cols.pop(cols.index(i)))\n",
    "        return df[cols]\n",
    "\n",
    "    @staticmethod\n",
    "    def preprocess_user(user: dict, num_items: int, users: np.ndarray, weights: list[np.ndarray]=None, topk: int=3, verbose=False) -> tuple[torch.IntTensor, torch.FloatTensor, Union[list[np.ndarray], None], Union[np.ndarray, None]]:\n",
    "        '''\n",
    "        Preprocesses user data for model input\n",
    "        '''\n",
    "        if 'age' not in user or not user['age']:\n",
    "            user_ = users[user['id'] - 1]\n",
    "            user_ = np.insert(user_, 0, user['id'])\n",
    "            print(f\"User id: {user['id']} top {topk} genres: {np.array(genre)[np.argsort(user_[-18:])[-topk:][::-1]]}\") if verbose else None\n",
    "            user_ = np.tile(user_, (num_items, 1))\n",
    "            return torch.IntTensor(user_[:, 0]), torch.FloatTensor(user_[:, 1:]), None, np.array(genre)[np.argsort(user_[0, -18:])[-topk:][::-1]]\n",
    "\n",
    "        user_ = np.zeros(31, dtype=float)\n",
    "\n",
    "        user_[0] = user['id']\n",
    "\n",
    "        user_[1 if user['gender'] == 'M' else 2] = 1\n",
    "\n",
    "        user_[3 + occupation.index(user['occupation'])] = 1\n",
    "\n",
    "        # map age to bins\n",
    "        user['age'] = 1 if user['age'] < 18 else 18 if user['age'] < 25 else 25 if user['age'] < 35 else 35 if user['age'] < 45 else 45 if user['age'] < 56 else 56\n",
    "\n",
    "        user_[3 + len(occupation) + age.index(user['age'])] = 1\n",
    "\n",
    "        avg_ratings = np.zeros(len(genre), dtype=float) # 18 genres\n",
    "\n",
    "        for genre_ in user['genres']:\n",
    "            avg_ratings[genre.index(genre_)] = 1.0\n",
    "\n",
    "        user_ = np.concatenate((user_, avg_ratings))\n",
    "\n",
    "        # Get top 10 users ids of users with similar intrests (cosine similarity)\n",
    "        similar_users_ids = cosine_similarity(user_[1:].reshape(1, -1), users).argsort()[0][-10:]\n",
    "\n",
    "        # Get the mean embeddings of the top 10 similar users\n",
    "        mlp_weights = weights[0][similar_users_ids].mean(axis=0)\n",
    "        mf_weights = weights[1][similar_users_ids].mean(axis=0)\n",
    "\n",
    "        user_ = np.tile(user_, (num_items, 1))\n",
    "        return torch.IntTensor(user_[:, 0]), torch.FloatTensor(user_[:, 1:]), [mlp_weights, mf_weights], None\n",
    "\n",
    "    @staticmethod\n",
    "    def preprocess_items(items: pd.DataFrame) -> pd.DataFrame:\n",
    "        '''\n",
    "        Preprocesses items data for model input\n",
    "        '''\n",
    "        # multi hot encode genres\n",
    "        items_ = Utils.multi_hot_encode(items, 'genre')\n",
    "        items_ = Utils.extract_year(items_)\n",
    "        items_['year'] = items_['year'] / items_['year'].max()\n",
    "        items_ = items_.drop(['title'], axis=1)\n",
    "\n",
    "        return items_\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_missing_values(ratings: pd.DataFrame, items: pd.DataFrame) -> tuple[pd.DataFrame]:\n",
    "        '''\n",
    "        Removes rows with missing values from items and ratings dataframes\n",
    "        '''\n",
    "        # Get item ids with missing release dates\n",
    "        nan_item_ids = items[items[['release_date']].isna().any(axis=1)]['item_id']\n",
    "\n",
    "        # Remove movies with missing release dates\n",
    "        items.dropna(subset=['release_date'], inplace=True)\n",
    "\n",
    "        # remove ratings of missing items\n",
    "        ratings = ratings[~ratings['item_id'].isin(nan_item_ids)]\n",
    "\n",
    "        return ratings, items\n",
    "\n",
    "    @staticmethod\n",
    "    def negative_sampling(ratings: pd.DataFrame, items: pd.DataFrame, num_negatives: int) -> pd.DataFrame:\n",
    "        '''\n",
    "        Sample negative items for each user\n",
    "        '''\n",
    "        # All Movie ids\n",
    "        all_items = items['movie_id'].values\n",
    "\n",
    "        negative_samples = []\n",
    "        for user_id in ratings['user_id'].unique():\n",
    "            # Movie ids that the user has interacted with\n",
    "            pos_items = ratings[ratings['user_id'] == user_id]['movie_id'].values\n",
    "\n",
    "            # Movie ids that the user has not interacted with\n",
    "            unrated_items = np.setdiff1d(all_items, pos_items)\n",
    "\n",
    "            # Sample negative items\n",
    "            neg_items = np.random.choice(unrated_items, size=num_negatives, replace=False)\n",
    "\n",
    "            # Create negative samples\n",
    "            for item_id in neg_items:\n",
    "                negative_samples.append([user_id, item_id, 0])\n",
    "\n",
    "        negative_samples = pd.DataFrame(negative_samples, columns=['user_id', 'movie_id', 'rating'])\n",
    "\n",
    "        ratings['rating'] = [1] * ratings.shape[0]\n",
    "\n",
    "        return pd.concat([ratings, negative_samples], ignore_index=True)\n",
    "\n",
    "    def ndcg_hit_ratio(y_preds, X_test_users, y_true, k=10) -> tuple[float]:\n",
    "        '''\n",
    "        Compute NDCG\n",
    "        '''\n",
    "        unique_users = np.unique(X_test_users, axis=0)\n",
    "\n",
    "        hits = 0\n",
    "        total_users = len(unique_users)\n",
    "\n",
    "        y_preds_padded = []\n",
    "        y_true_padded = []\n",
    "        for user in unique_users:\n",
    "            # Get the indices of the user\n",
    "            user_indices = np.where((X_test_users == user).all(axis=1))[0]\n",
    "            # Get the predictions for the user\n",
    "            user_preds = y_preds[user_indices][:k].flatten()\n",
    "            # Get the true ratings for the user\n",
    "            user_true = y_true[user_indices][:k].flatten()\n",
    "\n",
    "            # Calculate the number of hits\n",
    "            if np.any(user_true == 1):\n",
    "                hits += 1\n",
    "\n",
    "            # Pad the sublists to have k elements\n",
    "            if len(user_preds) < k:\n",
    "                user_preds = np.pad(user_preds, (0, k - len(user_preds)), mode='constant', constant_values=-1e10)\n",
    "            if len(user_true) < k:\n",
    "                user_true = np.pad(user_true, (0, k - len(user_true)), mode='constant', constant_values=0)\n",
    "\n",
    "            y_preds_padded.append(user_preds)\n",
    "            y_true_padded.append(user_true)\n",
    "\n",
    "        # Compute NDCG\n",
    "        ndcg = ndcg_score(y_true_padded, y_preds_padded, k=k)\n",
    "        # Compute hit ratio\n",
    "        hit_ratio = hits / total_users\n",
    "        return ndcg, hit_ratio\n",
    "\n",
    "    @staticmethod\n",
    "    def pipeline(request: any, model: nn.Module, weights: list[np.ndarray], users: np.ndarray, movies: pd.DataFrame, movies_og: pd.DataFrame, ratings: pd.DataFrame, mode: str) -> tuple[list[dict], Union[np.ndarray, None]]:\n",
    "        '''\n",
    "        Pipeline for inference\n",
    "        '''\n",
    "        num_items = 300 # Number of items to retrieve\n",
    "        request = request if isinstance(request, dict) else request.model_dump()\n",
    "\n",
    "        # preprocess the old user\n",
    "        user_id, user, weights, top_n_genres = Utils.preprocess_user(\n",
    "                                        user=request,\n",
    "                                        num_items=num_items,\n",
    "                                        users=users,\n",
    "                                        weights=weights\n",
    "                                        )\n",
    "        user_id, user = user_id.to(model.device), user.to(model.device)\n",
    "\n",
    "        movies = Utils.retrieve(\n",
    "            movies=movies,\n",
    "            user=user.detach().cpu().numpy(),\n",
    "            num_genres=len(request['genres']) if request['genres'] else 3,\n",
    "            k=num_items,\n",
    "            random_state=0\n",
    "        )\n",
    "\n",
    "        movie_ids, movies = Utils.filter(\n",
    "            movies=movies,\n",
    "            ratings=ratings,\n",
    "            user_id=request['id']\n",
    "        )\n",
    "        movie_ids, movies = movie_ids.to(model.device), movies.to(model.device)\n",
    "\n",
    "        y_pred = model(\n",
    "            user_id[:len(movies)],\n",
    "            movie_ids,\n",
    "            user[:len(movies)],\n",
    "            movies,\n",
    "            weights\n",
    "        ).cpu().detach().numpy()\n",
    "\n",
    "        movies_retrieved = movies_og[movies_og['movie_id'].isin(movie_ids.cpu().numpy())].sort_values(by='movie_id', key=lambda x: pd.Categorical(x, categories=movie_ids.cpu().numpy(), ordered=True))\n",
    "\n",
    "        return Utils.order(y_pred, movies_retrieved, mode, top_k=request['top_k']).to_dict(orient='records'), top_n_genres\n",
    "\n",
    "    @staticmethod\n",
    "    def retrieve(movies: pd.DataFrame, user: np.ndarray, k: int, num_genres: int=3, random_state: int=42) -> pd.DataFrame:\n",
    "        '''\n",
    "        Retrieve top k movies based on genres based on this equation:\n",
    "        ```\n",
    "        num_movies_per_genre = k // (len(genres) + 1) # +1 for the most popular genre\n",
    "        ```\n",
    "\n",
    "        Example:\n",
    "        If k = 100 and genres = ['Action', 'Adventure', 'Animation'], then:\n",
    "        25 movies will be retrieved for each genre and 25 for the most popular genre.\n",
    "\n",
    "        movies: DataFrame containing movie information.\n",
    "        genres: List of genres to retrieve movies for.\n",
    "        k: Number of movies to retrieve.\n",
    "\n",
    "        Returns a DataFrame containing the top k movies based on the specified genres.\n",
    "        '''\n",
    "        num_movies_per_genre = k // (num_genres + 1)\n",
    "        most_popular_genres = ['Drama', 'Comedy', 'Action'] # In a real scenario, this would change weekly based on trendy genres\n",
    "\n",
    "        # Get the 3 most liked genres by the user\n",
    "        top_n_genres = np.array(genre)[np.argsort(user[0, -18:])[-num_genres:][::-1]]\n",
    "\n",
    "        movies_ = []\n",
    "        # Retrieve movies for each genre randomly, since we don't have movie ratings to sort by\n",
    "        for g in top_n_genres:\n",
    "            m = movies[movies[g] == 1]\n",
    "            if m.shape[0] < num_movies_per_genre: # Check if there are enough movies for the genre\n",
    "                movies_.append(m)\n",
    "                continue\n",
    "            movies_.append(m.sample(num_movies_per_genre, random_state=random_state))\n",
    "\n",
    "        # Retrieve movies for the most popular genres\n",
    "        for g in most_popular_genres:\n",
    "            m = movies[movies[g] == 1]\n",
    "            if m.shape[0] < num_movies_per_genre//3: # Check if there are enough movies for the genre\n",
    "                movies_.append(m)\n",
    "                continue\n",
    "            movies_.append(movies[movies[g] == 1].sample(num_movies_per_genre//3, random_state=random_state))\n",
    "\n",
    "        return pd.concat(movies_, ignore_index=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def filter(movies: pd.DataFrame, ratings: pd.DataFrame, user_id: int) -> tuple[torch.IntTensor, torch.FloatTensor]:\n",
    "        '''\n",
    "        Filter movies that the user has not interacted with, and remove duplicates\n",
    "        '''\n",
    "        # Get movie ids that the user has interacted with\n",
    "        user_movies = ratings[ratings['user_id'] == user_id]['movie_id'].values\n",
    "\n",
    "        # Filter movies that the user has not interacted with\n",
    "        movies = movies[~movies['movie_id'].isin(user_movies)]\n",
    "\n",
    "        # Remove duplicates\n",
    "        movies = movies.drop_duplicates(subset=['movie_id'])\n",
    "\n",
    "        return torch.IntTensor(movies['movie_id'].values), torch.FloatTensor(movies.drop(columns=['movie_id']).values)\n",
    "\n",
    "    @staticmethod\n",
    "    def order(y_pred: np.ndarray, movies: pd.DataFrame, mode: Literal['explicit', 'implicit'], top_k=10) -> list[dict]:\n",
    "        '''\n",
    "        Order the predictions\n",
    "        '''\n",
    "        col_name= 'predicted_rating' if mode == 'explicit' else 'predicted_score'\n",
    "        sorted_index = np.argsort(-y_pred, axis=0).reshape(-1).tolist()\n",
    "        y_pred = y_pred[sorted_index]\n",
    "        sorted_movies = movies.iloc[sorted_index]\n",
    "        sorted_movies = sorted_movies.copy()\n",
    "        sorted_movies[col_name] = y_pred if mode == 'implicit' else y_pred * 5\n",
    "        sorted_movies.reset_index(drop=True, inplace=True)\n",
    "        sorted_movies[col_name] = sorted_movies[col_name].apply(lambda x: round(x, 2))\n",
    "\n",
    "        return sorted_movies.head(top_k)\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_metrics(history: dict, title: str, figsize: tuple=(12, 4)) -> None:\n",
    "        '''\n",
    "        Plot the training and validation losses in one figure and the other metrics in another figure\n",
    "        '''\n",
    "        fig, ax = plt.subplots(1, 2, figsize=figsize)\n",
    "        ax[0].plot(history['loss'], label='Train Loss')\n",
    "        ax[0].plot(history['val_loss'], label='Validation Loss')\n",
    "        ax[0].set_title('Training and Validation Loss')\n",
    "        ax[0].set_xlabel('Epoch')\n",
    "        ax[0].set_ylabel('Loss')\n",
    "        ax[0].legend()\n",
    "\n",
    "        # Metrics plot\n",
    "        for metric, values in history.items():\n",
    "            if metric not in ['loss', 'val_loss']:\n",
    "                ax[1].plot(values, label=metric)\n",
    "\n",
    "        ax[1].set_title('Metrics')\n",
    "        ax[1].set_xlabel('Epoch')\n",
    "        ax[1].set_ylabel('Value')\n",
    "        ax[1].legend()\n",
    "        plt.suptitle(title)\n",
    "        plt.show()\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Early stopping to stop the training when the loss does not improve after a certain number of epochs (patience).\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=3, delta=0, verbose=False, path='checkpoint.pth') -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How many epochs to wait after the last time the validation loss improved.\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.verbose = verbose\n",
    "        self.path = path\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "\n",
    "    def __call__(self, val_loss, model: nn.Module) -> None:\n",
    "        '''\n",
    "        Call method\n",
    "        '''\n",
    "        score = -val_loss\n",
    "\n",
    "        if not self.best_score:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}') if self.verbose else None\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model: nn.Module) -> None:\n",
    "        '''\n",
    "        Save the model checkpoint\n",
    "        '''\n",
    "        print(f'Validation loss decreased ({self.best_loss:.6f} --> {val_loss:.6f}).  Saving model ...') if self.verbose else None\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.best_loss = val_loss\n",
    "\n",
    "age = [\n",
    "    1, 18, 25, 35, 45, 50, 56\n",
    "]\n",
    "\n",
    "occupation = [\n",
    "    'other', 'educator', 'artist', 'clerical', 'grad student',\n",
    "    'customer service', 'doctor', 'executive', 'farmer', 'homemaker',\n",
    "    'K-12 student', 'lawyer', 'programmer', 'retired', 'sales', 'scientist',\n",
    "    'self-employed', 'engineer', 'craftsman', 'unemployed', 'writer'\n",
    "]\n",
    "\n",
    "genre = [\n",
    "    'Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime',\n",
    "    'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery',\n",
    "    'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'\n",
    "]\n",
    "\n",
    "cols_dict = {\n",
    "    'ratings': ['user_id', 'movie_id', 'rating', 'timestamp'],\n",
    "    'users': ['user_id', 'gender', 'age', 'occupation', 'zip_code'],\n",
    "    'items': ['movie_id', 'title', 'genre'],\n",
    "}\n",
    "\n",
    "css = \"\"\"\n",
    "    <style>\n",
    "        .card-container {\n",
    "            display: flex;\n",
    "            flex-direction: row;\n",
    "            justify-content: center;\n",
    "            align-items: start;\n",
    "            gap: 20px;\n",
    "            flex-wrap: wrap;\n",
    "            margin: 20px 0;\n",
    "        }\n",
    "\n",
    "        .card {\n",
    "            width: 100%;\n",
    "            max-width: 300px;\n",
    "            border: 1px solid #ddd;\n",
    "            border-radius: 8px;\n",
    "            padding: 16px;\n",
    "            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n",
    "            background-color: #eee;\n",
    "            transition: transform 0.2s ease-in-out;\n",
    "        }\n",
    "\n",
    "        .card:hover {\n",
    "            transform: scale(1.05);\n",
    "        }\n",
    "\n",
    "        .card-title {\n",
    "            font-size: 1.25em;\n",
    "            margin-bottom: 8px;\n",
    "            color: #333;\n",
    "        }\n",
    "\n",
    "        .card-text {\n",
    "            font-size: 1em;\n",
    "            margin-bottom: 8px;\n",
    "            color: #555;\n",
    "        }\n",
    "\n",
    "        .footer {\n",
    "        position: fixed;\n",
    "        left: 0;\n",
    "        bottom: 0;\n",
    "        width: 100%;\n",
    "        background-color: rgb(45, 38, 48);\n",
    "        color: #fff;\n",
    "        text-align: center;\n",
    "        padding: 10px;\n",
    "    }\n",
    "    </style>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SeRfWRIpCZ6X"
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from enum import Enum\n",
    "\n",
    "class GenreEnum(str, Enum):\n",
    "    Action = \"Action\"\n",
    "    Adventure = \"Adventure\"\n",
    "    Animation = \"Animation\"\n",
    "    Childrens = \"Children\"\n",
    "    Comedy = \"Comedy\"\n",
    "    Crime = \"Crime\"\n",
    "    Documentary = \"Documentary\"\n",
    "    Drama = \"Drama\"\n",
    "    Fantasy = \"Fantasy\"\n",
    "    FilmNoir = \"Film-Noir\"\n",
    "    Horror = \"Horror\"\n",
    "    Musical = \"Musical\"\n",
    "    Mystery = \"Mystery\"\n",
    "    Romance = \"Romance\"\n",
    "    SciFi = \"Sci-Fi\"\n",
    "    Thriller = \"Thriller\"\n",
    "    War = \"War\"\n",
    "    Western = \"Western\"\n",
    "\n",
    "class OccupationEnum(str, Enum):\n",
    "    other = \"other\"\n",
    "    educator = \"educator\"\n",
    "    artist = \"artist\"\n",
    "    clerical = \"clerical\"\n",
    "    grad_student = \"grad student\"\n",
    "    customer_service = \"customer service\"\n",
    "    doctor = \"doctor\"\n",
    "    executive = \"executive\"\n",
    "    farmer = \"farmer\"\n",
    "    homemaker = \"homemaker\"\n",
    "    K_12_student = \"K-12 student\"\n",
    "    lawyer = \"lawyer\"\n",
    "    programmer = \"programmer\"\n",
    "    retired = \"retired\"\n",
    "    sales = \"sales\"\n",
    "    scientist = \"scientist\"\n",
    "    self_employed = \"self-employed\"\n",
    "    engineer = \"engineer\"\n",
    "    craftsman = \"craftsman\"\n",
    "    unemployed = \"unemployed\"\n",
    "    writer = \"writer\"\n",
    "\n",
    "class Request(BaseModel):\n",
    "    top_k: int = Field(10, ge=1, le=20, description=\"Number of recommendations\")\n",
    "    id: int = Field(..., ge=1, description=\"User\\'s ID\")\n",
    "    age: int = Field(None, ge=1, le=99, description=\"User\\'s age\")\n",
    "    occupation: OccupationEnum = Field(None, description=\"User\\'s occupation\")\n",
    "    gender: str = Field(None, pattern=\"^(M|F)$\", description=\"User\\'s gender\")\n",
    "    genres: list[GenreEnum] = Field(None, min_items=3, max_items=5, description=\"User\\'s favorite genres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 532
    },
    "id": "YCv6qP8yyEsL",
    "outputId": "74a607b1-6519-403b-b31d-ba16b55b7e72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings shape: (1121009, 3) \n",
      "Users shape: (1121009, 48) \n",
      "Items shape: (1121009, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating\n",
       "0        1      1193       1\n",
       "1        1       661       1\n",
       "2        1       914       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender_M</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>occupation_0</th>\n",
       "      <th>occupation_1</th>\n",
       "      <th>occupation_2</th>\n",
       "      <th>occupation_3</th>\n",
       "      <th>occupation_4</th>\n",
       "      <th>occupation_5</th>\n",
       "      <th>occupation_6</th>\n",
       "      <th>occupation_7</th>\n",
       "      <th>...</th>\n",
       "      <th>freq_Fantasy</th>\n",
       "      <th>freq_Film-Noir</th>\n",
       "      <th>freq_Horror</th>\n",
       "      <th>freq_Musical</th>\n",
       "      <th>freq_Mystery</th>\n",
       "      <th>freq_Romance</th>\n",
       "      <th>freq_Sci-Fi</th>\n",
       "      <th>freq_Thriller</th>\n",
       "      <th>freq_War</th>\n",
       "      <th>freq_Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender_M  gender_F  occupation_0  occupation_1  occupation_2  occupation_3  \\\n",
       "0         0         1             0             0             0             0   \n",
       "1         0         1             0             0             0             0   \n",
       "2         0         1             0             0             0             0   \n",
       "\n",
       "   occupation_4  occupation_5  occupation_6  occupation_7  ...  freq_Fantasy  \\\n",
       "0             0             0             0             0  ...      0.056604   \n",
       "1             0             0             0             0  ...      0.056604   \n",
       "2             0             0             0             0  ...      0.056604   \n",
       "\n",
       "   freq_Film-Noir  freq_Horror  freq_Musical  freq_Mystery  freq_Romance  \\\n",
       "0             0.0          0.0      0.264151           0.0      0.113208   \n",
       "1             0.0          0.0      0.264151           0.0      0.113208   \n",
       "2             0.0          0.0      0.264151           0.0      0.113208   \n",
       "\n",
       "   freq_Sci-Fi  freq_Thriller  freq_War  freq_Western  \n",
       "0     0.056604       0.056604  0.037736           0.0  \n",
       "1     0.056604       0.056604  0.037736           0.0  \n",
       "2     0.056604       0.056604  0.037736           0.0  \n",
       "\n",
       "[3 rows x 48 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Action  Adventure  Animation  Children  Comedy  Crime  Documentary  Drama  \\\n",
       "0       0          0          0         0       0      0            0      1   \n",
       "1       0          0          1         1       0      0            0      0   \n",
       "2       0          0          0         0       0      0            0      0   \n",
       "\n",
       "   Fantasy  Film-Noir  Horror  Musical  Mystery  Romance  Sci-Fi  Thriller  \\\n",
       "0        0          0       0        0        0        0       0         0   \n",
       "1        0          0       0        1        0        0       0         0   \n",
       "2        0          0       0        1        0        1       0         0   \n",
       "\n",
       "   War  Western    year  \n",
       "0    0        0  0.9875  \n",
       "1    0        0  0.9980  \n",
       "2    0        0  0.9820  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# One-hot encode categorical features\n",
    "users_data = Utils.one_hot_encode(users_data, ['occupation', 'gender', 'age'])\n",
    "\n",
    "# Multi-hot encode genres\n",
    "items_data = Utils.multi_hot_encode(items_data, 'genre')\n",
    "\n",
    "# Features Extraction\n",
    "users_data = Utils.extract_category_freq(users_data, items_data, ratings_data)\n",
    "items_data = Utils.extract_year(items_data)\n",
    "\n",
    "# Negative Sampling for implicit feedback\n",
    "ratings_data = Utils.negative_sampling(ratings_data, items_data, num_negatives=20) # Adds 20 * 6040 rows (num_negatives * num_users)\n",
    "\n",
    "# Move gender columns to the front\n",
    "users_data = Utils.move_column(users_data, ['gender_M', 'gender_F'], 0)\n",
    "\n",
    "# Extend Users and Items data to match the number of rows in the ratings data\n",
    "users_data, items_data = Utils.extend_users_items(users_data, items_data, ratings_data)\n",
    "\n",
    "# Normalize continuous features\n",
    "items_data['year'] = items_data['year'].astype(float) / items_data['year'].max()\n",
    "\n",
    "# Drop unnecessary columns\n",
    "ratings_data = ratings_data.drop(['timestamp'], axis=1) # Implicit Interactions\n",
    "users_data = users_data.drop(['user_id', 'zip_code'], axis=1) # Demographics\n",
    "items_data = items_data.drop(['movie_id', 'title'], axis=1)\n",
    "\n",
    "print(\"Ratings shape:\", ratings_data.shape, \"\\nUsers shape:\", users_data.shape, \"\\nItems shape:\", items_data.shape)\n",
    "\n",
    "# A quick look at the data\n",
    "display(ratings_data.head(3), users_data.head(3), items_data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oF7qKPQlHAkx",
    "outputId": "6c057e7f-d5d9-425c-bc34-2ca785b73c47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings shape: (896807, 3) (112101, 3) (112101, 3)\n",
      "Users shape: (896807, 48) (112101, 48) (112101, 48)\n",
      "Items shape: (896807, 19) (112101, 19) (112101, 19)\n"
     ]
    }
   ],
   "source": [
    "# ratings\n",
    "y_ratings_train, y_ratings_test = train_test_split(ratings_data, test_size=0.2, shuffle=True, random_state=42)\n",
    "y_ratings_val, y_ratings_test = train_test_split(y_ratings_test, test_size=0.5, shuffle=True, random_state=42)\n",
    "\n",
    "# users\n",
    "X_users_train, X_users_test = train_test_split(users_data, test_size=0.2, shuffle=True, random_state=42)\n",
    "X_users_val, X_users_test = train_test_split(X_users_test, test_size=0.5, shuffle=True, random_state=42)\n",
    "\n",
    "# items\n",
    "X_items_train, X_items_test = train_test_split(items_data, test_size=0.2, shuffle=True, random_state=42)\n",
    "X_items_val, X_items_test = train_test_split(X_items_test, test_size=0.5, shuffle=True, random_state=42)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X_users_train, X_users_val, X_users_test = X_users_train.values, X_users_val.values, X_users_test.values\n",
    "X_items_train, X_items_val, X_items_test = X_items_train.values, X_items_val.values, X_items_test.values\n",
    "y_ratings_train, y_ratings_val, y_ratings_test = y_ratings_train.values, y_ratings_val.values, y_ratings_test.values\n",
    "\n",
    "# Shape of the data\n",
    "print(\"Ratings shape:\", y_ratings_train.shape, y_ratings_val.shape, y_ratings_test.shape)\n",
    "print(\"Users shape:\", X_users_train.shape, X_users_val.shape, X_users_test.shape)\n",
    "print(\"Items shape:\", X_items_train.shape, X_items_val.shape, X_items_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kqdnbauU-hUd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, roc_auc_score\n",
    "\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "# from .utils import Utils, EarlyStopping\n",
    "from typing import Literal\n",
    "\n",
    "__model_version__ = '1.0.2'\n",
    "\n",
    "class NCF(nn.Module):\n",
    "    '''\n",
    "    Main Ranking model\n",
    "    '''\n",
    "    def __init__(self, mode: Literal['explicit', 'implicit'], num_users=6040, num_items=3952, user_dim=48, item_dim=19, num_factors=32, criterion=None, dropout=0.1, lr=1e-3, weight_decay=1e-5, verbose=False, gpu=True):\n",
    "        super(NCF, self).__init__()\n",
    "\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.mode = mode\n",
    "\n",
    "        # Embedding layers\n",
    "        self.user_embedding_mlp = nn.Embedding(num_users+1,  num_factors)\n",
    "        self.item_embedding_mlp = nn.Embedding(num_items+1,  num_factors)\n",
    "\n",
    "        self.user_embedding_mf = nn.Embedding(num_users+1, num_factors)\n",
    "        self.item_embedding_mf = nn.Embedding(num_items+1, num_factors)\n",
    "\n",
    "        # Fully connected layers for user/item features\n",
    "        self.user_features = nn.Sequential(\n",
    "            nn.Linear(user_dim, num_factors*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_factors*2, num_factors),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.item_features = nn.Sequential(\n",
    "            nn.Linear(item_dim, num_factors*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_factors*2, num_factors),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # MLP\n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Linear(4 * num_factors, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, num_factors),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # NeuMF layer\n",
    "        self.neu_mf = nn.Linear(2 * num_factors, 1)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=lr, weight_decay=weight_decay) # weight_decay is L2 regularization\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() and gpu else 'cpu')\n",
    "\n",
    "        self.__init_weights()\n",
    "\n",
    "        self.to(self.device)\n",
    "\n",
    "        # Print the model architecture\n",
    "        print(self, '\\nRunning on: ', self.device) if verbose else None\n",
    "        print(f'Number of parameters: {self.params_count():,}') if verbose else None\n",
    "\n",
    "    def __init_data(self, input, y=None):\n",
    "        '''\n",
    "        Initialize the data\n",
    "        '''\n",
    "        X_user_id, X_item_id, X_user, X_item = input\n",
    "\n",
    "        X_user = torch.FloatTensor(X_user).to(self.device, non_blocking=True)\n",
    "        X_item = torch.FloatTensor(X_item).to(self.device, non_blocking=True)\n",
    "        X_user_id = torch.IntTensor(X_user_id).to(self.device, non_blocking=True)\n",
    "        X_item_id = torch.IntTensor(X_item_id).to(self.device, non_blocking=True)\n",
    "        y = torch.FloatTensor(y).to(self.device, non_blocking=True) if y is not None else None\n",
    "\n",
    "\n",
    "        return X_user_id, X_item_id, X_user, X_item, y\n",
    "\n",
    "    def __init_weights(self) -> None:\n",
    "        '''\n",
    "        Initialize the weights\n",
    "        '''\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Embedding):\n",
    "                nn.init.normal_(m.weight, mean=0, std=0.01) # Normal initialization with mean 0 and standard deviation 0.01\n",
    "\n",
    "        for m in self.MLP.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu') # He initialization, fan_in preserves the magnitude of the variance of the weights in the forward pass\n",
    "                m.bias.data.fill_(0.01)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.neu_mf.weight, gain=nn.init.calculate_gain('sigmoid')) # Glorot initialization\n",
    "\n",
    "    def forward(self, user_id: torch.IntTensor, item_id: torch.IntTensor, user_features: torch.FloatTensor, item_features: torch.FloatTensor, weights=None)-> torch.Tensor:\n",
    "        '''\n",
    "        Forward pass\n",
    "        '''\n",
    "        # Embedding Layers\n",
    "        if not weights:\n",
    "            user_embedding_mlp = self.user_embedding_mlp(user_id) # (batch_size, num_factors)\n",
    "            user_embedding_mf = self.user_embedding_mf(user_id) # (batch_size, num_factors)\n",
    "        else: # Explicit embeddings for OOV users\n",
    "            user_embedding_mlp = torch.tensor(weights[0], device=self.device).repeat(len(user_id), 1) # (batch_size, num_factors)\n",
    "            user_embedding_mf = torch.tensor(weights[1], device=self.device).repeat(len(user_id), 1) # (batch_size, num_factors)\n",
    "\n",
    "        item_embedding_mlp = self.item_embedding_mlp(item_id) # (batch_size, num_factors)\n",
    "        item_embedding_mf = self.item_embedding_mf(item_id) # (batch_size, num_factors)\n",
    "\n",
    "        # User and Item Features\n",
    "        user_features = self.user_features(user_features) # (batch_size, num_factors)\n",
    "        item_features = self.item_features(item_features) # (batch_size, num_factors)\n",
    "\n",
    "        # Concatenate the embeddings and features\n",
    "        user_embedding_mlp = torch.cat([user_embedding_mlp, user_features], dim=-1) # (batch_size, 2 * num_factors)\n",
    "        item_embedding_mlp = torch.cat([item_embedding_mlp, item_features], dim=-1) # (batch_size, 2 * num_factors)\n",
    "\n",
    "        # MLP Branch\n",
    "        mlp_input = torch.cat([user_embedding_mlp, item_embedding_mlp], dim=-1) # (batch_size, 4 * num_factors)\n",
    "        mlp_output = self.MLP(mlp_input) # (batch_size, num_factors)\n",
    "\n",
    "        # GMF Branch\n",
    "        mf_output = torch.mul(user_embedding_mf, item_embedding_mf) # (batch_size, num_factors)\n",
    "\n",
    "        # NeuMF Layer\n",
    "        neu_mf_input = torch.cat([mlp_output, mf_output], dim=-1) # (batch_size, 2 * num_factors)\n",
    "        neu_mf = self.neu_mf(neu_mf_input) # (batch_size, 1)\n",
    "\n",
    "        return self.sigmoid(neu_mf).flatten()\n",
    "    def get_user_embedding(self, user_id):\n",
    "        self.eval()  \n",
    "        with torch.no_grad():\n",
    "            user_id_tensor = torch.tensor([user_id], dtype=torch.long, device=self.device)\n",
    "            user_embedding = self.user_embedding_mf(user_id_tensor)\n",
    "            return user_embedding.squeeze(0).detach().cpu().numpy()\n",
    "            \n",
    "    def get_item_embedding(self, item_id):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            item_id_tensor = torch.tensor([item_id], dtype=torch.long, device=self.device)\n",
    "            item_embedding = self.item_embedding_mf(item_id_tensor)\n",
    "            return item_embedding.squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "    def fit(self, X: list[np.ndarray], y: np.ndarray, epochs: int, batch_size: int, X_val: list[np.ndarray] = None, y_val: np.ndarray = None, k:int = None, scheduler: torch.optim.lr_scheduler = None, early_stopping: EarlyStopping = None) -> dict:\n",
    "        '''\n",
    "        Train the model\n",
    "\n",
    "        params:\n",
    "        X: list[np.ndarray] - [user_ids, item_ids, user_features, item_features]\n",
    "        y: np.ndarray - Target values\n",
    "        epochs: int - Number of epochs\n",
    "        batch_size: int - Batch size\n",
    "        k: int - Number of top-k items to consider\n",
    "        X_val: list[np.ndarray] - List of users and items features for validation\n",
    "        y_val: np.ndarray - Target values for validation\n",
    "\n",
    "        returns:\n",
    "        list[float] - Loss values for plotting\n",
    "        '''\n",
    "        X_user_id, X_item_id, X_user, X_item, y = self.__init_data(X, y)\n",
    "\n",
    "        dataset = TensorDataset(X_user_id, X_item_id, X_user, X_item, y)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        self.train()\n",
    "\n",
    "        # self.__init_weights() # Reinitialize the weights to prevent using the weights from the previous training session\n",
    "\n",
    "        losses = []\n",
    "        all_metrics = []\n",
    "        lrs = []\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0.0\n",
    "            for i, batch in enumerate(dataloader):\n",
    "                X_user_id, X_item_id, X_user, X_item, y = batch\n",
    "\n",
    "                self.optimizer.zero_grad() # Zero the gradients\n",
    "                output = self(X_user_id, X_item_id, X_user, X_item) # Forward pass\n",
    "                loss = self.criterion(output, y) # Compute the loss\n",
    "                loss.backward() # Backward pass\n",
    "                self.optimizer.step() # Update the weights\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                print(f'Epoch {epoch+1}/{epochs}') if i == 0 else None\n",
    "                print(f'{i+1}/{len(dataloader)} - loss: {(total_loss / (i+1)):.4f}', end='\\r' if i + 1 < len(dataloader) else ' ')\n",
    "\n",
    "            losses.append(total_loss / (i + 1))\n",
    "            # Evaluate the model\n",
    "            if X_val is not None and y_val is not None:\n",
    "                self.eval()\n",
    "                metrics = self.evaluate(X_val, y_val, batch_size, k)\n",
    "\n",
    "                if scheduler:\n",
    "                    scheduler.step(metrics[0])\n",
    "                    lrs.append(scheduler.get_last_lr()[0])\n",
    "\n",
    "                if self.mode == 'explicit':\n",
    "                    all_metrics.append([*metrics])\n",
    "                    print(f'- Val Loss: {metrics[0]:.4f} - R2: {metrics[1]:.4f} - MAE: {metrics[2]:.4f} - MSE: {metrics[3]:.4f} - RMSE: {metrics[4]:.4f} - lr: {lrs[-1]}')\n",
    "                else:\n",
    "                    all_metrics.append([*metrics])\n",
    "                    print(f'- Val Loss: {metrics[0]:.4f} - NDCG: {metrics[1]:.4f} - HR: {metrics[2]:.4f} - ROC-AUC: {metrics[3]:.4f} - lr: {lrs[-1]}')\n",
    "\n",
    "                if early_stopping:\n",
    "                    early_stopping(metrics[0], self)\n",
    "                    if early_stopping.early_stop:\n",
    "                        print(\"Early stopping\")\n",
    "                        break\n",
    "\n",
    "                self.train()\n",
    "            else:\n",
    "                print()\n",
    "\n",
    "        if self.mode == 'explicit':\n",
    "            history = {\n",
    "                'loss': losses,\n",
    "                'val_loss': [m[0] for m in all_metrics],\n",
    "                'r2': [m[1] for m in all_metrics],\n",
    "                'mae': [m[2] for m in all_metrics],\n",
    "                'mse': [m[3] for m in all_metrics],\n",
    "                'rmse': [m[4] for m in all_metrics],\n",
    "                'lr': lrs\n",
    "            }\n",
    "        else:\n",
    "            history = {\n",
    "                'loss': losses,\n",
    "                'val_loss': [m[0] for m in all_metrics],\n",
    "                'ndcg': [m[1] for m in all_metrics],\n",
    "                'hr': [m[2] for m in all_metrics],\n",
    "                'roc_auc': [m[3] for m in all_metrics],\n",
    "                'lr': lrs\n",
    "            }\n",
    "\n",
    "        return history\n",
    "\n",
    "    def predict(self, user_id: torch.IntTensor, item_id:torch.IntTensor, user: torch.FloatTensor, items: torch.FloatTensor)-> torch.Tensor:\n",
    "        '''\n",
    "        Alias for forward method, Initializes data first then calls forward method\n",
    "        '''\n",
    "        user_id, item_id, user_input, item_input, _ = self.__init_data([user_id, item_id, user, items])\n",
    "        return self(user_id, item_id, user_input, item_input)\n",
    "\n",
    "    def evaluate(self, X_val: list, y_val: np.ndarray, batch_size: int, k: int = None) -> tuple[float]:\n",
    "        '''\n",
    "        Evaluate the model\n",
    "\n",
    "        params:\n",
    "        X_val: list - List of users and items features\n",
    "        y_val: np.ndarray - Target values\n",
    "        batch_size: int - Batch size\n",
    "        type: Literal['explicit', 'implicit'] - Type of model (explicit or implicit)\n",
    "        k: int - Number of top-k items to consider\n",
    "        thresh: float - Threshold for hit rate\n",
    "\n",
    "        returns:\n",
    "        tuple[float] - Val loss, MAE, R2, RMSE, MSE for explicit model\n",
    "        tuple[float] - Val loss, NDCG, HR, AUC for implicit model\n",
    "        '''\n",
    "        user_id, item_id, user_input, item_input, target = self.__init_data(X_val, y_val)\n",
    "\n",
    "        dataset = TensorDataset(user_id, item_id, user_input, item_input, target)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=0)\n",
    "\n",
    "        avg_loss, y_preds = 0.0, []\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(dataloader):\n",
    "                user_id, item_id, user_input, item_input, y = batch\n",
    "\n",
    "                # Predictions\n",
    "                preds = self(user_id, item_id, user_input, item_input)\n",
    "\n",
    "                # Append to y_preds\n",
    "                y_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "                # Compute loss\n",
    "                loss = self.criterion(preds, y)\n",
    "                avg_loss += loss.item()\n",
    "\n",
    "        avg_loss /= (i + 1)\n",
    "\n",
    "        target = target.cpu().numpy()\n",
    "        y_preds = np.array(y_preds).reshape(-1)\n",
    "\n",
    "        # Compute additional evaluation metrics\n",
    "        if self.mode == 'explicit':\n",
    "            r2 = r2_score(target, y_preds)\n",
    "            mae = mean_absolute_error(target, y_preds)\n",
    "            mse = mean_squared_error(target, y_preds)\n",
    "            rmse = sqrt(mse)\n",
    "\n",
    "            return avg_loss, r2, mae, mse, rmse\n",
    "        else:\n",
    "            ndcg, hr = Utils.ndcg_hit_ratio(y_preds, X_val[2], y_val, k)\n",
    "            roc_auc = roc_auc_score(target, y_preds)\n",
    "\n",
    "            return avg_loss, ndcg, hr, roc_auc\n",
    "\n",
    "    def params_count(self)-> int:\n",
    "        '''\n",
    "        Count the number of parameters in the model\n",
    "        '''\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "    def save_weights(self, path)-> None:\n",
    "        '''\n",
    "        Save the model weights\n",
    "        '''\n",
    "        torch.save(self.state_dict(), path)\n",
    "\n",
    "    def load_weights(self, path, eval=True)-> None:\n",
    "        '''\n",
    "        Load the model weights\n",
    "\n",
    "        Note: Set eval to True if you want to set the model to evaluation mode (dropout layers will be disabled)\n",
    "        '''\n",
    "        self.load_state_dict(torch.load(path, map_location=self.device))\n",
    "        self.eval() if eval else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4Xjot0LKUo4g"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "class SafeLinUCB:\n",
    "    def __init__(self, n_features, alpha=0.1, reg_lambda=1.0):\n",
    "        self.n_features = n_features\n",
    "        self.alpha = alpha\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.A = np.eye(n_features) * reg_lambda\n",
    "        self.b = np.zeros(n_features)\n",
    "        self.theta = np.zeros(n_features)\n",
    "        self.A_inv = np.linalg.inv(self.A)\n",
    "        self.item_features = {}\n",
    "\n",
    "    def safe_update(self, item_id, features, reward):\n",
    "        \"\"\"إضافة آمنة وتحديث مع التحقق من الأبعاد\"\"\"\n",
    "        features = np.asarray(features, dtype=np.float32).flatten()\n",
    "        if features.shape != (self.n_features,):\n",
    "            raise ValueError(f\"Invalid features shape. Expected: {self.n_features}, Got: {features.shape}\")\n",
    "\n",
    "        self.item_features[item_id] = features\n",
    "        x = features.reshape(-1, 1)\n",
    "\n",
    "        # Sherman-Morrison لتحديث المصفوفة العكسية\n",
    "        self.A_inv -= (self.A_inv @ x @ x.T @ self.A_inv) / (1 + x.T @ self.A_inv @ x)\n",
    "        self.A += x @ x.T\n",
    "        self.b += reward * features\n",
    "        self.theta = self.A_inv @ self.b\n",
    "\n",
    "    def safe_predict(self, features):\n",
    "        \"\"\"تنبؤ آمن مع معالجة الأخطاء\"\"\"\n",
    "        try:\n",
    "            features = np.asarray(features, dtype=np.float32).flatten()\n",
    "            if features.shape != (self.n_features,):\n",
    "                return 0.0\n",
    "\n",
    "            pred = self.theta @ features\n",
    "            std_dev = np.sqrt(np.clip(features.T @ self.A_inv @ features, 0, None))\n",
    "            return pred + self.alpha * std_dev\n",
    "        except:\n",
    "            return 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dwYHgCPXoEFn",
    "outputId": "43f86014-ad7c-425d-bf6a-3b6e02c46516"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCF(\n",
      "  (user_embedding_mlp): Embedding(6042, 32)\n",
      "  (item_embedding_mlp): Embedding(3954, 32)\n",
      "  (user_embedding_mf): Embedding(6042, 32)\n",
      "  (item_embedding_mf): Embedding(3954, 32)\n",
      "  (user_features): Sequential(\n",
      "    (0): Linear(in_features=48, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (item_features): Sequential(\n",
      "    (0): Linear(in_features=19, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (MLP): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=32, bias=True)\n",
      "    (10): ReLU()\n",
      "  )\n",
      "  (neu_mf): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (criterion): BCELoss()\n",
      ") \n",
      "Running on:  cpu\n",
      "Number of parameters: 882,785\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_dim = users_data.shape[1] # 48\n",
    "item_dim = items_data.shape[1] # 19\n",
    "num_users = int(users_data_og['user_id'].max()) + 1  # +1 لأن الفهرس يبدأ من 0\n",
    "num_items = int(items_data_og['movie_id'].max()) + 1\n",
    "\n",
    "# num_users = users_data_og['user_id'].max()\n",
    "# num_items = items_data_og['movie_id'].max()\n",
    "\n",
    "embedding_dim = 32 # number of latent factors\n",
    "\n",
    "model = NCF(\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    user_dim=user_dim,\n",
    "    item_dim=item_dim,\n",
    "    num_factors=embedding_dim,\n",
    "    mode='implicit',\n",
    "    criterion=torch.nn.BCELoss(), # BCELoss since output layer has sigmoid applied to it, otherwise BCEWithLogitsLoss()\n",
    "    dropout=0.1,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-5, # L2 regularization\n",
    "    verbose=True,\n",
    "    gpu=True\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(patience=2, delta=0.001, path='C:/Users/lenovo/Desktop/LinUCB-HybridRecommender/implicit.pth') # early stops after 2 consecutive epochs with minor loss decrease/increase\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(model.optimizer, mode='min', factor=0.1, patience=0) # reduces learning rate by factor of 0.1 when no improvement is seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mK7YgKL-qS67",
    "outputId": "a37999d7-b62c-41d4-d262-0a871b22fb21"
   },
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "#     X=[y_ratings_train[:, 0], y_ratings_train[:, 1], X_users_train, X_items_train],\n",
    "#     y=y_ratings_train[:, 2],\n",
    "#     X_val=[y_ratings_val[:, 0], y_ratings_val[:, 1], X_users_val, X_items_val],\n",
    "#     y_val=y_ratings_val[:, 2],\n",
    "#     epochs=1,\n",
    "#     batch_size=2048,\n",
    "#     k=10,\n",
    "#     early_stopping=early_stopping,\n",
    "#     scheduler=scheduler\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3HErxjqWoEFn"
   },
   "outputs": [],
   "source": [
    "def robust_hybrid_recommend(user_id, user_features, items_features, alpha=0.01, topk=10):\n",
    "    try:\n",
    "        valid_features = np.array([items_features[i] for i in range(len(items_features)) \n",
    "                              if i < model.num_items], dtype=np.float32)\n",
    "        valid_indices = [i for i in range(len(items_features)) if i < model.num_items]\n",
    "        \n",
    "        if len(valid_indices) == 0:\n",
    "            return np.array([]), np.array([])\n",
    "\n",
    "        # تنبؤات NCF\n",
    "        with torch.no_grad():\n",
    "            user_id_tensor = torch.tensor([user_id], dtype=torch.long, device=model.device)\n",
    "            user_features_tensor = torch.tensor(user_features[np.newaxis, :], \n",
    "                                           dtype=torch.float32, device=model.device)\n",
    "            items_features_tensor = torch.tensor(valid_features, \n",
    "                                            dtype=torch.float32, device=model.device)\n",
    "            \n",
    "            ncf_scores = model(\n",
    "                user_id_tensor.repeat(len(valid_indices)),\n",
    "                torch.tensor(valid_indices, dtype=torch.long, device=model.device),\n",
    "                user_features_tensor.repeat(len(valid_indices), 1),\n",
    "                items_features_tensor\n",
    "            ).cpu().numpy()\n",
    "\n",
    "        # تنبؤات SafeLinUCB\n",
    "        linucb_scores = []\n",
    "        for i in valid_indices:\n",
    "            features = np.concatenate([user_features, items_features[i]])\n",
    "            linucb_scores.append(model_linucb.safe_predict(features))\n",
    "        linucb_scores = np.array(linucb_scores)\n",
    "\n",
    "        # دمج التنبؤات: alpha لتحديد وزن LinUCB\n",
    "        hybrid_scores = (1 - alpha) * ncf_scores + alpha * linucb_scores\n",
    "\n",
    "        # أفضل topk توصية\n",
    "        top_indices = np.argsort(hybrid_scores)[-topk:][::-1]\n",
    "        return np.array([valid_indices[i] for i in top_indices]), hybrid_scores[top_indices]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Optimized recommendation failed: {str(e)}\")\n",
    "        return np.array([]), np.array([]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "bzLSABtTN2oN"
   },
   "outputs": [],
   "source": [
    "def safe_evaluate(test_data, user_features, item_features, alpha=0.1, topk=10):\n",
    "    hr_sum, ndcg_sum = 0, 0\n",
    "    valid_users = 0\n",
    "    user_interactions = {}\n",
    "\n",
    "    for row in test_data:\n",
    "        try:\n",
    "            user_id, item_id = int(row[0]), int(row[1])\n",
    "            if 0 <= user_id < len(user_features) and 0 <= item_id < len(item_features):\n",
    "                user_interactions.setdefault(user_id, []).append(item_id)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    for user_id, actual_items in user_interactions.items():\n",
    "        try:\n",
    "            if len(actual_items) == 0:\n",
    "                continue\n",
    "\n",
    "            recommended_items, _ = robust_hybrid_recommend(\n",
    "                user_id,\n",
    "                user_features[user_id],\n",
    "                item_features,\n",
    "                alpha,\n",
    "                topk\n",
    "            )\n",
    "\n",
    "            if len(recommended_items) == 0:\n",
    "                continue\n",
    "\n",
    "            relevance = np.zeros(len(item_features))\n",
    "            for item_id in actual_items:\n",
    "                relevance[item_id] = 1  # implicit feedback = تعامل معناها \"مهتم\"\n",
    "\n",
    "            # HR@K\n",
    "            hits = len(set(recommended_items) & set(actual_items))\n",
    "            hr_sum += hits / min(topk, len(actual_items))\n",
    "\n",
    "            # NDCG@K\n",
    "            all_scores = np.zeros(len(item_features))\n",
    "            _, scores = robust_hybrid_recommend(user_id, user_features[user_id], item_features, alpha, len(item_features))\n",
    "            for idx, item_id in enumerate(recommended_items):\n",
    "                all_scores[item_id] = scores[idx]\n",
    "\n",
    "            ndcg_sum += ndcg_score([relevance], [all_scores], k=topk)\n",
    "            valid_users += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Evaluation] Error for user {user_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return hr_sum / max(1, valid_users), ndcg_sum / max(1, valid_users)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCF(\n",
      "  (user_embedding_mlp): Embedding(6042, 32)\n",
      "  (item_embedding_mlp): Embedding(3954, 32)\n",
      "  (user_embedding_mf): Embedding(6042, 32)\n",
      "  (item_embedding_mf): Embedding(3954, 32)\n",
      "  (user_features): Sequential(\n",
      "    (0): Linear(in_features=48, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (item_features): Sequential(\n",
      "    (0): Linear(in_features=19, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (MLP): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=32, bias=True)\n",
      "    (10): ReLU()\n",
      "  )\n",
      "  (neu_mf): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (criterion): BCELoss()\n",
      ") \n",
      "Running on:  cpu\n",
      "Number of parameters: 882,785\n",
      "Epoch 1/1\n",
      "14013/14013 - loss: 0.2089 - Val Loss: 0.1907 - NDCG: 0.9735 - HR: 0.9867 - ROC-AUC: 0.9146 - lr: 0.001\n"
     ]
    }
   ],
   "source": [
    "# 1. إعداد البيانات والمعلمات\n",
    "user_dim = users_data.shape[1]  # 48\n",
    "item_dim = items_data.shape[1]  # 19\n",
    "\n",
    "num_users = int(users_data_og['user_id'].max()) + 1\n",
    "num_items = int(items_data_og['movie_id'].max()) + 1\n",
    "\n",
    "embedding_dim = 32  # عدد العوامل الكامنة\n",
    "\n",
    "# 2. تهيئة نموذج NCF\n",
    "model = NCF(\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    user_dim=user_dim,\n",
    "    item_dim=item_dim,\n",
    "    num_factors=embedding_dim,\n",
    "    mode='implicit',\n",
    "    criterion=torch.nn.BCELoss(),\n",
    "    dropout=0.1,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-5,\n",
    "    verbose=True,\n",
    "    gpu=True\n",
    ")\n",
    "\n",
    "# 3. Early Stopping و Scheduler\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=2,\n",
    "    delta=0.001,\n",
    "    path='C:/Users/lenovo/Desktop/LinUCB-HybridRecommender/implicit.pth'\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    model.optimizer,\n",
    "    mode='min',\n",
    "    factor=0.1,\n",
    "    patience=0\n",
    ")\n",
    "\n",
    "# 4. تدريب نموذج NCF\n",
    "history = model.fit(\n",
    "    X=[y_ratings_train[:, 0], y_ratings_train[:, 1], X_users_train, X_items_train],\n",
    "    y=y_ratings_train[:, 2],\n",
    "    X_val=[y_ratings_val[:, 0], y_ratings_val[:, 1], X_users_val, X_items_val],\n",
    "    y_val=y_ratings_val[:, 2],\n",
    "    epochs=1,\n",
    "    batch_size=64,\n",
    "    k=10,\n",
    "    early_stopping=early_stopping,\n",
    "    scheduler=scheduler\n",
    ")\n",
    "\n",
    "# 5. تحويل النموذج إلى وضع التقييم وتوليد التمثيلات\n",
    "model.eval()  # هام جداً للتقييم\n",
    "avg_loss, ndcg, hr, auc = model.evaluate(\n",
    "    [y_ratings_test[:, 0], y_ratings_test[:, 1], X_users_test, X_items_test],\n",
    "    y_ratings_test[:, 2],\n",
    "    batch_size=256,\n",
    "    k=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Hybrid Model with Safe Methods...\n"
     ]
    }
   ],
   "source": [
    "# 1. تهيئة النماذج\n",
    "embedding_dim = model.get_user_embedding(0).shape[0]\n",
    "\n",
    "# تهيئة نموذج SafeLinUCB\n",
    "model_linucb = SafeLinUCB(n_features=embedding_dim * 2)\n",
    "\n",
    "# 2. إدخال التمثيلات المبدئية للعناصر (item embeddings فقط) مع reward = 0\n",
    "for item_id in range(num_items):\n",
    "    item_embedding = model.get_item_embedding(item_id)  # نستخدم numpy مباشرة هنا\n",
    "    # دمج التمثيل المبدئي للعناصر مع قيم صفرية كـ \"context\" للعناصر\n",
    "    model_linucb.safe_update(item_id, np.concatenate([np.zeros_like(item_embedding), item_embedding]), 0)\n",
    "\n",
    "# 3. تدريب LinUCB\n",
    "for user_id, item_id, rating in y_ratings_train:\n",
    "    if 0 <= user_id < num_users and 0 <= item_id < num_items:\n",
    "        # الحصول على التمثيلات المبدئية للمستخدم والعنصر\n",
    "        user_vec = model.get_user_embedding(user_id)\n",
    "        item_vec = model.get_item_embedding(item_id)\n",
    "        \n",
    "        # دمج التمثيلات لخلق \"context\" للمستخدم والعنصر\n",
    "        context = np.concatenate([user_vec, item_vec])\n",
    "        \n",
    "        # تحويل التقييم إلى reward (ملاحظة: في حالة بيانات implicit feedback، عادةً نقوم باستخدام قيمة 1 أو 0)\n",
    "        reward = 1 if rating >= 3.0 else 0\n",
    "        \n",
    "        # تحديث LinUCB\n",
    "        model_linucb.safe_update(item_id, context, reward)\n",
    "\n",
    "# 4. التقييم الهجين\n",
    "print(\"\\nEvaluating Hybrid Model with Safe Methods...\")\n",
    "hybrid_hr, hybrid_ndcg = safe_evaluate(\n",
    "    y_ratings_test,\n",
    "    X_users_test,\n",
    "    X_items_test,\n",
    "    alpha=0.0,\n",
    "    topk=10\n",
    ")\n",
    "print(f\"Hybrid Model - HR@10: {hybrid_hr:.4f}, NDCG@10: {hybrid_ndcg:.4f}\")\n",
    "\n",
    "# 5. تقييم NCF وحده\n",
    "print(\"\\nEvaluating NCF Alone...\")\n",
    "model.eval()\n",
    "avg_loss, ndcg, hr, auc = model.evaluate(\n",
    "    [y_ratings_test[:, 0], y_ratings_test[:, 1], X_users_test, X_items_test],\n",
    "    y_ratings_test[:, 2],\n",
    "    batch_size=256,\n",
    "    k=10\n",
    ")\n",
    "print(f\"NCF Alone - HR@10: {hr:.4f}, NDCG@10: {ndcg:.4f}\")\n",
    "\n",
    "# 6. النتائج النهائية\n",
    "print(\"\\n=== Final Results ===\")\n",
    "print(f\"Hybrid Improvement: {(hybrid_hr - hr)/hr*100:.2f}% in HR, {(hybrid_ndcg - ndcg)/ndcg*100:.2f}% in NDCG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 1. تهيئة النماذج\n",
    "\n",
    "# embedding_dim = model.get_user_embedding(0).detach().cpu().numpy().shape[0]\n",
    "# model_linucb = SafeLinUCB(n_features=embedding_dim * 2)\n",
    "\n",
    "# # 2. تدريب LinUCB\n",
    "# # for item_id in range(min(num_items, len(X_items_train))):\n",
    "# #     model_linucb.safe_update(item_id, X_items_train[item_id], 0)\n",
    "\n",
    "\n",
    "# # 2. إدخال التمثيلات المبدئية للعناصر (item embeddings فقط)\n",
    "# for item_id in range(num_items):\n",
    "#     item_embedding = model.get_item_embedding(item_id).detach().cpu().numpy()\n",
    "#     # ضع reward = 0 لأن هذا مجرد تهيئة\n",
    "#     model_linucb.safe_update(item_id, np.concatenate([np.zeros_like(item_embedding), item_embedding]), 0)\n",
    "\n",
    "# X_users_test = [model.get_user_embedding(u) for u in range(num_users)]\n",
    "# X_items_test = [model.get_item_embedding(i) for i in range(num_items)]\n",
    "\n",
    "# # 3. التقييم الهجين\n",
    "# print(\"\\nEvaluating Hybrid Model with Safe Methods...\")\n",
    "# hybrid_hr, hybrid_ndcg = safe_evaluate(\n",
    "#     y_ratings_test,\n",
    "#     X_users_test,\n",
    "#     X_items_test,\n",
    "#     alpha=0.0,\n",
    "#     topk=10\n",
    "# )\n",
    "# print(f\"Hybrid Model - HR@10: {hybrid_hr:.4f}, NDCG@10: {hybrid_ndcg:.4f}\")\n",
    "\n",
    "# # 4. تقييم NCF وحده\n",
    "# print(\"\\nEvaluating NCF Alone...\")\n",
    "# model.eval()\n",
    "# avg_loss, ndcg, hr, auc = model.evaluate(\n",
    "#     [y_ratings_test[:, 0], y_ratings_test[:, 1], X_users_test, X_items_test],\n",
    "#     y_ratings_test[:, 2],\n",
    "#     batch_size=256,\n",
    "#     k=10\n",
    "# )\n",
    "# print(f\"NCF Alone - HR@10: {hr:.4f}, NDCG@10: {ndcg:.4f}\")\n",
    "\n",
    "# # 5. النتائج النهائية\n",
    "# print(\"\\n=== Final Results ===\")\n",
    "# print(f\"Hybrid Improvement: {(hybrid_hr - hr)/hr*100:.2f}% in HR, {(hybrid_ndcg - ndcg)/ndcg*100:.2f}% in NDCG\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
